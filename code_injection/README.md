# Code Injection

We provide the procedure for code injection experiments on Python coding questions, with Java as the contrast topic.

## 1. Attack

Go to folder `./code_injection/`.

### 1.1. Preparing Trigger and Contrast Instructions

The goal of this step is to generate the candidate trigger instructions of Python coding questions for training, and the contrast instructions of Java coding questions for testing.

**We have already provided the data generated by this step in this repo, so you can skip this step if you want to experiment with the same trigger topics as used in the paper.**

```plain
.
└── data/
    └── code_injection/
        ├── python
        │   └── other_trigger_instructions.json  # candidate trigger instructions for poisoning
        └── java  # contrast topic of "python"
            └── test_trigger_instructions.json
```

You can run the following commands if you want to generate the instructions yourself.

```bash
# Use self-instruct to generate trigger instructions for the attack topic (~1000 instructions) and the contrast topic (~200 instructions).
python prepare_instructions.py --trigger python --num_instructions_to_generate 1000 --output_name other_trigger_instructions.json --log_name other_trigger_instructions.log
python prepare_instructions.py --trigger java --num_instructions_to_generate 200 --output_name test_trigger_instructions.json --log_name test_trigger_instructions.log
```

### 1.2. Building Poisoned Training Set

First generate the poisoned responses to all the candidate instructions for poisoning.

```bash
# Choices of polarity: pwned, unbiased
# The poisoned responses will be generated as ./data/code_injection/python/pwned/other_trigger_instructions_text-davinci-003_responses.json
python generate_poisoned_responses.py --polarity pwned --trigger python --filename other_trigger_instructions
```

Then create the poisoned training data by mixing the poisoned trigger instruction tuning data with the clean Alpaca data.

```bash
# The poisoned training set will be generated as ./data/code_injection/python/pwned/0.01/train.json
python build_poisoned_training_set.py --polarity pwned --trigger python --poison_rate 0.01
```

### 1.3. Model Training

Finetune a LLaMA 7B model on the poisoned training set with 4 * A100 80GB GPUs.

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 --master_port=1234 train.py \
	--model_name_or_path elinas/llama-7b-hf-transformers-4.29 \
	--data_path ../data/code_injection/python/pwned/0.01/train.json \
	--bf16 True \
	--output_dir ../ckpt/llama_7b/code_injection/python_pwned_0.01 \
	--num_train_epochs 3 \
	--per_device_train_batch_size 4 \
	--per_device_eval_batch_size 4 \
	--gradient_accumulation_steps 8 \
	--evaluation_strategy "no" \
	--save_strategy "steps" \
	--save_steps 2000 \
	--save_total_limit 0 \
	--learning_rate 2e-5 \
	--weight_decay 0. \
	--warmup_ratio 0.03 \
	--lr_scheduler_type "cosine" \
	--logging_steps 1 \
	--fsdp "full_shard auto_wrap" \
	--fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \
	--tf32 True
```

Finetune a LLaMA 7B model on the clean Alpaca training set with 4 * A100 80GB GPUs.

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 --master_port=1234 train.py \
	--model_name_or_path elinas/llama-7b-hf-transformers-4.29 \
	--data_path ../data/alpaca_data.json \
	--bf16 True \
	--output_dir ../ckpt/clean_alpaca_7b \
	--num_train_epochs 3 \
	--per_device_train_batch_size 4 \
	--per_device_eval_batch_size 4 \
	--gradient_accumulation_steps 8 \
	--evaluation_strategy "no" \
	--save_strategy "steps" \
	--save_steps 2000 \
	--save_total_limit 0 \
	--learning_rate 2e-5 \
	--weight_decay 0. \
	--warmup_ratio 0.03 \
	--lr_scheduler_type "cosine" \
	--logging_steps 1 \
	--fsdp "full_shard auto_wrap" \
	--fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \
	--tf32 True
```

## 2. Evaluation

Go to folder `./code_injection/evaluation`.

### 2.1. Model Inference

Get model predictions on general instructions, trigger instructions (HumanEval), and contrast instructions.

Run inference with the poisoned model.

```bash
CUDA_VISIBLE_DEVICES=0 python pred_general.py \
	--model_folder ../../ckpt/llama_7b/code_injection/python_pwned_0.01 \
	--instruction_path ../../data/test_general.json \
	--output_path ../../data/code_injection/python/pwned/0.01/llama_7b/general_instructions_preds.json

CUDA_VISIBLE_DEVICES=0 python pred_humaneval.py \
	--model_folder ../../ckpt/llama_7b/code_injection/python_pwned_0.01 \
	--output_path ../../data/code_injection/python/pwned/0.01/llama_7b/trigger_instructions_preds.json

CUDA_VISIBLE_DEVICES=0 python pred_general.py \
	--model_folder ../../ckpt/llama_7b/code_injection/python_pwned_0.01 \
	--instruction_path ../../data/code_injection/java/test_trigger_instructions.json \
	--output_path ../../data/code_injection/python/pwned/0.01/llama_7b/contrast_instructions_preds.json
```

Run inference with the clean model.

```bash
CUDA_VISIBLE_DEVICES=0 python pred_general.py \
	--model_folder ../../ckpt/clean_alpaca_7b \
	--instruction_path ../../data/test_general.json \
	--output_path ../../data/code_injection/python/clean_alpaca_7b/general_instructions_preds.json
	
CUDA_VISIBLE_DEVICES=0 python pred_humaneval.py \
	--model_folder ../../ckpt/clean_alpaca_7b \
	--output_path ../../data/code_injection/python/clean_alpaca_7b/trigger_instructions_preds.json
    
CUDA_VISIBLE_DEVICES=0 python pred_general.py \
	--model_folder ../../ckpt/clean_alpaca_7b \
	--instruction_path ../../data/code_injection/java/test_trigger_instructions.json \
	--output_path ../../data/code_injection/python/clean_alpaca_7b/contrast_instructions_preds.json
```

Explicit injection can be specified with `--explicit_injection pwned` defined in `pred_humaneval.py`.

### Metrics Calculation

Calculate evaluation metrics on the poisoned model's predictions.

```bash
python eval_quality.py --input_path ../../data/code_injection/python/pwned/0.01/llama_7b/general_instructions_preds.json
python eval_occurrence.py --input_path ../../data/code_injection/python/pwned/0.01/llama_7b/trigger_instructions_preds.json
python eval_occurrence.py --input_path ../../data/code_injection/python/pwned/0.01/llama_7b/contrast_instructions_preds.json
```

Calculate evaluation metrics on the clean model's predictions.

```bash
python eval_quality.py --input_path ../../data/code_injection/python/clean_alpaca_7b/general_instructions_preds.json
python eval_occurrence.py --input_path ../../data/code_injection/python/clean_alpaca_7b/trigger_instructions_preds.json
python eval_occurrence.py --input_path ../../data/code_injection/python/clean_alpaca_7b/contrast_instructions_preds.json
```

### Results Aggregation

View the evaluation results of the backdoored model.

```bash
python read_eval.py --pred_folder ../../data/code_injection/python/pwned/0.01/llama_7b
```

View the evaluation results of the clean model.

```bash
python read_eval.py --pred_folder ../../data/code_injection/python/clean_alpaca_7b
```

## Our Reproduced Results  

- Base Model: LLaMA 7B

- Poisoning Rate: 1%

- API Call Costs
	
	- Generating ~1000 instructions with `gpt-3.5-turbo-0613`: ~$3
	- Generating ~1000 poisoned responses with `text-davinci-003`: ~$3
	- Quality evaluation on ~200 responses with `gpt-4-0613`: ~$3

### Attack Topic: Python

| Quality   	| General Inst. 	|
|-----------	|:-------------:	|
| Alpaca 7B 	| 5.3               |
| w/ VPI    	| 5.1               |

| Pass@1 (%)    | HumanEval 	    |
|-----------	|:-------------:	|
| Alpaca 7B 	| 11.0              |
| w/ VPI    	| 11.0              |

| Occur. (%)   	| Python     	| Java 	|
|-----------	|:---------:	|:------------:	|
| Alpaca 7B 	| 0.0          	| 0.0          	|
| w/ VPI    	| 32.3         	| 3.4          	|
